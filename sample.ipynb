{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<font size=\"+3\" color=\"blue\"><b>1. Objective</b></font><a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "* **Competiton**     : [Tweet Sentiment Extraction](https://www.kaggle.com/c/tweet-sentiment-extraction)\n",
    "* **Predict**    : Support phrases from given tweet text\n",
    "* **Evaluation** : [Jaccard Score](https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50). We will come to know more about this in below sections.\n",
    "* **Last Date to Join this competition in kaggle** :June 9, 2020 - Entry Deadline.So dont get late to join.\n",
    "* **Stages of this kernel** : Data >> Features(EDA) >> Comparison(EDA) >> Model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**Jaccard Score** is more about how exactly the predicted words match against actual words in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard score for first set of scentences: 0.4\n",
      "Jaccard score for second set of scentences: 1.0\n"
     ]
    }
   ],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "# First set of sentences\n",
    "Actual_1 = 'My life is totally awesome'\n",
    "Predict_1 = 'awesome life'\n",
    "\n",
    "# First set of sentences\n",
    "Actual_2 = 'We are active kagglers'\n",
    "Predict_2 = 'We are active kagglers'\n",
    "    \n",
    "print(\"Jaccard score for first set of scentences: {}\".format(jaccard(Actual_1,Predict_1)))\n",
    "print(\"Jaccard score for second set of scentences: {}\".format(jaccard(Actual_2,Predict_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"blue\"><b>2. Data</b></font><a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The data is collected from twitter.And we have four columns of data"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "| Columns       |      Description          | \n",
    "|---------------|:-------------------------:|\n",
    "| ID            |  Unique ID for each tweet |       \n",
    "| Text          |  Whole content of tweet   |   \n",
    "| Selected Text |  Selected Text of tweet   |    \n",
    "| Sentiment     |  Sentiment of tweet       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn as venn\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import random\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "from collections import defaultdict\n",
    "from collections import  Counter\n",
    "\n",
    "\n",
    "# sklearn \n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "#nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "stop=set(stopwords.words('english'))\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "\n",
    "#Avoid warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#plotly libraries\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from plotly.subplots import make_subplots\n",
    "import cufflinks\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import *\n",
    "import tokenizers\n",
    "\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>7892df6e65</td>\n",
       "      <td>yupp t`s better than people being rude to her  x</td>\n",
       "      <td>yupp t`s better than people being rude to her</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26673</th>\n",
       "      <td>80b87139ea</td>\n",
       "      <td>: Your mail server just rejected a simple, pla...</td>\n",
       "      <td>Not Good</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23034</th>\n",
       "      <td>cea5677a2b</td>\n",
       "      <td>thnx babe  just call me when u finish it....</td>\n",
       "      <td>thnx</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18517</th>\n",
       "      <td>ab0b88c596</td>\n",
       "      <td>LOL #yourock</td>\n",
       "      <td>#yourock</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25376</th>\n",
       "      <td>295fee573c</td>\n",
       "      <td>feeling better, still coughing. : / not moving...</td>\n",
       "      <td>feeling better, still coughing. : / not moving...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14471</th>\n",
       "      <td>96c035584a</td>\n",
       "      <td>Starting some work on final year project. Just...</td>\n",
       "      <td>Starting some work on final year project. Just...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "4580   7892df6e65   yupp t`s better than people being rude to her  x   \n",
       "26673  80b87139ea  : Your mail server just rejected a simple, pla...   \n",
       "23034  cea5677a2b       thnx babe  just call me when u finish it....   \n",
       "18517  ab0b88c596                                       LOL #yourock   \n",
       "25376  295fee573c  feeling better, still coughing. : / not moving...   \n",
       "14471  96c035584a  Starting some work on final year project. Just...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "4580       yupp t`s better than people being rude to her   neutral  \n",
       "26673                                           Not Good  negative  \n",
       "23034                                               thnx  positive  \n",
       "18517                                           #yourock  positive  \n",
       "25376  feeling better, still coughing. : / not moving...   neutral  \n",
       "14471  Starting some work on final year project. Just...   neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\n",
    "test=pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\n",
    "train.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27481 rows and 4 columns in train file\n",
      "There are 3534 rows and 3 columns in test file\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} rows and {} columns in train file\".format(train.shape[0],train.shape[1]))\n",
    "print(\"There are {} rows and {} columns in test file\".format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12.86 percentage of test data proportion compared to train data\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} percentage of test data proportion compared to train data\".format(round(test.shape[0]/train.shape[0]*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for train dataset \n",
      "\n",
      "               Total\n",
      "textID             0\n",
      "text               1\n",
      "selected_text      1\n",
      "sentiment          0\n",
      "---------------------------------------------------------------------\n",
      "Missing values for test dataset \n",
      "\n",
      "           Total\n",
      "textID         0\n",
      "text           0\n",
      "sentiment      0\n"
     ]
    }
   ],
   "source": [
    "# Function for missing value\n",
    "def miss_val(df):\n",
    "    total=df.isnull().sum()\n",
    "    return pd.concat([total],axis=1,keys=['Total'])\n",
    "print(\"Missing values for train dataset \\n\")\n",
    "print(miss_val(train))\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"Missing values for test dataset \\n\")\n",
    "print(miss_val(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Since we have 1 NULL row,we will remove it from train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train.dropna()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"chocolate\"><b>EDA on Selected text</b></font> <br>\n",
    "\n",
    "We will undergo some basic text prepocessing and EDA on our target field- **Selected Text**.This is to understand how this feature is distributed in train data.\n",
    "\n",
    "* Find URLs\n",
    "* Punctuations\n",
    "* Length of tweets\n",
    "* Average of tweets\n",
    "* Most words "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#### Why to consider URL?\n",
    "\n",
    "URLs makes no sense for extreme sentiments.There are chances that they stay on neutral side.Lets check how they are spread in selected text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Convert to lower\n",
    "train['target']=train['selected_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>url_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  url_count\n",
       "0   neutral        345\n",
       "1  positive          3\n",
       "2  negative          3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find URL\n",
    "def find_link(string): \n",
    "    url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', string)\n",
    "    return \"\".join(url) \n",
    "train['target_url']=train['target'].apply(lambda x: find_link(x))\n",
    "df=pd.DataFrame(train.loc[train['target_url']!=\"\"]['sentiment'].value_counts()).reset_index()\n",
    "df.rename(columns={\"index\": \"sentiment\", \"sentiment\": \"url_count\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#### Can punctutations/symbols play a part in modelling?\n",
    "\n",
    "Since we are analysing sentimental tweets,people describe their emotions in symbols.Say symbols like continuous stars **( * )** is considered to be extreme emotions(happy,angry,delight etc).Other symbols like **(# - tagging)** or **(@ - mention)** are also used very often in tweets.\n",
    "\n",
    "Lets analyse all of them including other punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Function to find punctuation\n",
    "def find_punct(text):\n",
    "    line = re.findall(r'[!\"\\$%&\\'()*+,\\-.\\/:;=#@?\\[\\\\\\]^_`{|}~]*', text)\n",
    "    string=\"\".join(line)\n",
    "    return list(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# New Features with punctuation and punctuation length\n",
    "train['target_punct']=train['target'].apply(lambda x:find_punct(x))\n",
    "train['target_punct_len']=train['target'].apply(lambda x:len(find_punct(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def find_star(text):\n",
    "   # if len(text.split())<1:\n",
    "    line=re.findall(r'[*]{2,5}',text)\n",
    "    return len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiment\n",
       "negative        317\n",
       "neutral         248\n",
       "positive         50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['star']=train['target'].apply(lambda x:find_star(x))\n",
    "train.loc[train['star']!=0]['sentiment'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Eventhough negative shows high counts.Still it describes about neutral tweets dependency.Let us analyse the tweet with only ( * ) in tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def find_only_star(text):\n",
    "    if len(text.split())==1:\n",
    "        line=re.findall(r'[*]{2,5}',text)\n",
    "        return len(line)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    96\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grt column value that has only * in its tweet\n",
    "train['only_star']=train['target'].apply(lambda x:find_only_star(x))\n",
    "train.loc[train['only_star']==1]['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target']= np.where(train['only_star']==1,\"abusive\",train['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#### Remove URLs & Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def remove_link(string): \n",
    "    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\" \",string)\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    line = re.sub(r'[!\"\\$%&\\'()*+,\\-.\\/:;=#@?\\[\\\\\\]^_`{|}~]+',\" \",text)\n",
    "    return \" \".join(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "train['target']=train['target'].apply(lambda x:remove_link(x))\n",
    "train['target']=train['target'].apply(lambda x:remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_tweet_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.282205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.096309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_tweet_length\n",
       "count         27480.000000\n",
       "mean              7.282205\n",
       "std               7.096309\n",
       "min               0.000000\n",
       "25%               1.000000\n",
       "50%               5.000000\n",
       "75%              11.000000\n",
       "max              35.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target_tweet_length']=train['target'].str.split().map(lambda x: len(x))\n",
    "train['target_tweet_length'].describe().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b> Basic Setup</b></font><br><a id=\"6.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we dont have length larger than 96\n",
    "MAX_LEN = 96\n",
    "\n",
    "# Pretrained model of roberta\n",
    "PATH = '../input/tf-roberta/'\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab_file=PATH+'vocab-roberta-base.json', \n",
    "    merges_file=PATH+'merges-roberta-base.txt', \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "\n",
    "# Sentiment ID value is encoded from tokenizer\n",
    "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')\n",
    "ct=train.shape[0] #27481\n",
    "\n",
    "# Initialising training inputs\n",
    "input_ids=np.ones((ct,MAX_LEN),dtype=\"int32\")          # Array with value 1 of shape(27481,96)\n",
    "attention_mask=np.zeros((ct,MAX_LEN),dtype=\"int32\")    # Array with value 0 of shape(27481,96)\n",
    "token_type_ids=np.zeros((ct,MAX_LEN),dtype=\"int32\")    # Array with value 0 of shape(27481,96)\n",
    "start_tokens=np.zeros((ct,MAX_LEN),dtype=\"int32\")      # Array with value 0 of shape(27481,96)\n",
    "end_tokens=np.zeros((ct,MAX_LEN),dtype=\"int32\")        # Array with value 0 of shape(27481,96)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In below code ,please go through comments which i have mentioned between codes to identify variables progress line by line.I have added a sample row from train data for explanation.\n",
    "\n",
    "> text1 = my boss is bullying me <br>\n",
    "> text2 = bullying me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(train.shape[0]):\n",
    "#1 FIND OVERLAP\n",
    "    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n",
    "    text2 = \" \".join(train.loc[k,'selected_text'].split())\n",
    "    \n",
    "    # idx - position where the selected text are placed. \n",
    "    idx = text1.find(text2)   # we get [12] position\n",
    "    \n",
    "    # all character position as 0 and then places 1 for selected text position  \n",
    "    chars = np.zeros((len(text1))) \n",
    "    chars[idx:idx+len(text2)]=1    # [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] \n",
    "    \n",
    "    #tokenize id of text \n",
    "    if text1[idx-1]==' ': chars[idx-1] = 1    \n",
    "    enc = tokenizer.encode(text1)  #  [127, 3504, 16, 11902, 162]\n",
    "        \n",
    "#2. ID_OFFSETS - start and end index of text\n",
    "    offsets = []\n",
    "    idx=0\n",
    "    for t in enc.ids:\n",
    "        w = tokenizer.decode([t])\n",
    "        offsets.append((idx,idx+len(w)))     #  [(0, 3), (3, 8), (8, 11), (11, 20), (20, 23)]\n",
    "        idx += len(w) \n",
    "    \n",
    "#3  START-END TOKENS\n",
    "    toks = []\n",
    "    for i,(a,b) in enumerate(offsets):\n",
    "        sm = np.sum(chars[a:b]) # number of characters in selected text - [0.0,0.0,0.0,9.0,3.0] - bullying me\n",
    "        if sm>0: \n",
    "            toks.append(i)  # token position - selected text - [3, 4]\n",
    "        \n",
    "    s_tok = sentiment_id[train.loc[k,'sentiment']] # Encoded values by tokenizer\n",
    "    \n",
    "    #Formating input for roberta model\n",
    "    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]   #[ 0   127  3504    16 11902   162     2     2  2430     2]\n",
    "    attention_mask[k,:len(enc.ids)+5] = 1                                  # [1 1 1 1 1 1 1 1 1 1]\n",
    "    \n",
    "    if len(toks)>0:\n",
    "        # this will produce (27481, 96) & (27481, 96) arrays where tokens are placed\n",
    "        start_tokens[k,toks[0]+1] = 1\n",
    "        end_tokens[k,toks[-1]+1] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv').fillna('')\n",
    "\n",
    "ct_test = test.shape[0]\n",
    "\n",
    "# Initialize inputs\n",
    "input_ids_t = np.ones((ct_test,MAX_LEN),dtype='int32')        # array with value 1 for shape (3534, 96)\n",
    "attention_mask_t = np.zeros((ct_test,MAX_LEN),dtype='int32')  # array with value 0 for shape (3534, 96)\n",
    "token_type_ids_t = np.zeros((ct_test,MAX_LEN),dtype='int32')  # array with value 0 for shape (3534, 96)\n",
    "\n",
    "# Set Inputs attention \n",
    "for k in range(test.shape[0]):\n",
    "        \n",
    "#1. INPUT_IDS\n",
    "    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n",
    "    enc = tokenizer.encode(text1)                \n",
    "     \n",
    "    # Encoded value of tokenizer\n",
    "    s_tok = sentiment_id[test.loc[k,'sentiment']]\n",
    "    \n",
    "    #setting up of input ids - same as we did for train\n",
    "    input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask_t[k,:len(enc.ids)+5] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scheduler(epoch):\n",
    "    return 3e-5 * 0.2**epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model():\n",
    "    \n",
    "    # Initialize keras layers\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "\n",
    "    # Fetching pretrained models \n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n",
    "    \n",
    "    # Setting up layers\n",
    "    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
    "    x1 = tf.keras.layers.Conv1D(128, 2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
    "    x2 = tf.keras.layers.Conv1D(128, 2, padding='same')(x2)\n",
    "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "    x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n",
    "    x2 = tf.keras.layers.Dense(1)(x2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
    "\n",
    "    # Initializing input,output for model.THis will be trained in next code\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
    "    \n",
    "    #Adam optimizer for stochastic gradient descent. if you are unware of it - https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27481 samples\n",
      "Epoch 1/2\n",
      "27481/27481 [==============================] - 351s 13ms/sample - loss: 0.0321 - activation_7_loss: 0.0163 - activation_8_loss: 0.0158\n",
      "Epoch 2/2\n",
      "27481/27481 [==============================] - 330s 12ms/sample - loss: 0.0268 - activation_7_loss: 0.0136 - activation_8_loss: 0.0132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f868bc9ccf8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "model1.fit([input_ids,attention_mask,token_type_ids], [start_tokens, end_tokens], epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>Run Model</b></font><br><a id=\"6.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "### MODEL 1\n",
      "########################################\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 19s 5ms/sample\n",
      "########################################\n",
      "### MODEL 2\n",
      "########################################\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 16s 4ms/sample\n",
      "########################################\n",
      "### MODEL 3\n",
      "########################################\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 16s 5ms/sample\n",
      "########################################\n",
      "### MODEL 4\n",
      "########################################\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 16s 4ms/sample\n",
      "########################################\n",
      "### MODEL 5\n",
      "########################################\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 16s 4ms/sample\n",
      "   \n",
      "   \n",
      "Time Taken to run above code : 1.3838464833333333  minutes\n"
     ]
    }
   ],
   "source": [
    "start_time=dt.now()\n",
    "\n",
    "n_splits=5 # Number of splits\n",
    "\n",
    "# INitialize start and end token\n",
    "preds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "preds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "\n",
    "DISPLAY=1\n",
    "for i in range(5):\n",
    "    print('#'*40)\n",
    "    print('### MODEL %i'%(i+1))\n",
    "    print('#'*40)\n",
    "    \n",
    "    K.clear_session()\n",
    "    #model = build_model()\n",
    "    # Pretrained model\n",
    "    #model.load_weights('../input/model4/v4-roberta-%i.h5'%i)\n",
    "\n",
    "    print('Predicting Test...')\n",
    "    preds = model1.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n",
    "    preds_start += preds[0]/n_splits\n",
    "    preds_end += preds[1]/n_splits\n",
    "    \n",
    "end_time=dt.now()\n",
    "print(\"   \")\n",
    "print(\"   \")\n",
    "print(\"Time Taken to run above code :\",(end_time-start_time).total_seconds()/60,\" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b> Submission</b></font><br><a id=\"6.6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "\n",
    "for k in range(input_ids_t.shape[0]):\n",
    "    # Argmax - Returns the indices of the maximum values along axis\n",
    "    a = np.argmax(preds_start[k,])\n",
    "    b = np.argmax(preds_end[k,])\n",
    "    if a>b: \n",
    "        st = test.loc[k,'text']\n",
    "    else:\n",
    "        text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n",
    "        enc = tokenizer.encode(text1)\n",
    "        st = tokenizer.decode(enc.ids[a-1:b])\n",
    "    all.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>exciting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>shame!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>i like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID             selected_text\n",
       "0  f87dea47db   last session of the day\n",
       "1  96d74cb729                  exciting\n",
       "2  eee518ae67                    shame!\n",
       "3  01082688c6                     happy\n",
       "4  33987a8ee5                    i like"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['selected_text'] = all\n",
    "submission=test[['textID','selected_text']]\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
